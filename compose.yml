services:
  db:
    image: postgres:16
    container_name: crm_postgres
    environment:
      POSTGRES_DB: postgres
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: postgres
    ports:
      - "5434:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: [ "CMD-SHELL", "pg_isready --dbname=postgres --username=postgres" ]
      interval: 5s
      timeout: 5s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер лога (10 мегабайт)
        max-file: "3"     # Число файлов при ротации


  backend:
    build: ./backend
    container_name: crm_backend
    env_file:
      - .env  # Загружаем переменные из .env
    environment:
      DATABASE_URL: postgresql://postgres:postgres@db:5432/postgres
      FLASK_ENV: production
    ports:
      - "5000:5000"
    volumes:
      - backend_storage:/app/storage
    depends_on:
      db:
        condition: service_healthy
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер лога (10 мегабайт)
        max-file: "3"     # Число файлов при ротации


  nginx:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: crm_nginx
    ports:
      - "8383:80" # Публикуем порт 80 для доступа
    depends_on:
      - backend
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер лога (10 мегабайт)
        max-file: "3"     # Число файлов при ротации

  backup:
    image: amazon/aws-cli:2.13.7
    container_name: crm_backup
    env_file:
      - .env
    depends_on:
      - db
    # Монтируем том backend_storage, чтобы скопировать файлы
    volumes:
      - backend_storage:/data_to_backup:ro
    command: >
      sh -c "
      # 1. Делаем дамп базы в /tmp
      pg_dump -h db -U postgres -d postgres > /tmp/db_backup.sql &&
      echo 'Дамп базы выполнен.' &&

      # 2. Загружаем нижесозданный дамп в S3
      aws s3 cp /tmp/db_backup.sql s3://${S3_BUCKET_NAME}/db_backup_$(date +%Y%m%d_%H%M%S).sql
                --endpoint-url ${S3_ENDPOINT_URL} &&
      echo 'Дамп базы загружен в S3.' &&

      # 3. Синхронизируем данные из backend_storage
      aws s3 sync /data_to_backup s3://${S3_BUCKET_NAME}/backend_storage
                  --endpoint-url ${S3_ENDPOINT_URL} &&
      echo 'Файлы из backend_storage синхронизированы.'
      "
    logging:
      driver: "json-file"
      options:
        max-size: "10m"   # Максимальный размер лога (10 мегабайт)
        max-file: "3"     # Число файлов при ротации




volumes:
  postgres_data:
  backend_storage:
